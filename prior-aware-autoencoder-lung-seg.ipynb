{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Partial re-implementation of [Prior-aware autoencoders for lung pathology segmentation](https://www.sciencedirect.com/science/article/pii/S1361841522001384)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This paper is made up by 3 models:\n",
    "\n",
    "1. a Partial Convolutionl Neural Network (PCNN) written as an autoencoder\n",
    "2. a Normal Appearance Autoencoder model (NAA)\n",
    "3. the Prior UNet which predicts the lung pathology segmentation mask.\n",
    "\n",
    "This notebook will implement 2 and 3 the same way as the paper, but will the [Semantic Diffusion Model](https://github.com/WeilunWang/semantic-diffusion-model) instead for 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import os\n",
    "from PIL import Image"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Module 1: Semantic Diffusion Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directly inference from the trained SDM model to generate pathlogy free images\n",
    "# by running the /scripts/luna16.sh under the Semantic Diffusion Model directory\n",
    "\n",
    "# Prepare training and test dataset\n",
    "LESION_PATH = \"/home/user/data/prior_train/lesion\"\n",
    "LESION_FREE_PATH = \"/home/user/data/prior_train/lesion-free\"\n",
    "\n",
    "class NAAImageDataset(Dataset):\n",
    "  def __init__(self, lesion_path, lesion_free_path):\n",
    "    self.lesion_path = lesion_path\n",
    "    self.lesion_free_path = lesion_free_path\n",
    "    self.file_list = os.listdir(self.lesion_path)\n",
    "  \n",
    "  def __len__(self):\n",
    "    return len(self.file_list)\n",
    "  \n",
    "  def __getitem__(self, idx):\n",
    "    filename = self.file_list[idx]\n",
    "    lesion_image = Image.open()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Module 2: Normal Appearance Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Normal Apperance Autoencoder (NAA). It consists of an input layer of size 512, 5 hidden layers of size 256, 128, 64, 64, 64 and a sampling layer for mean and logvar of size 64\n",
    "# Define a convolution layer where each conv block consists of a conv2d layer, a batchnorm layer, then another conv2d layer followed by another batch normalization layer and finally a relu layer\n",
    "class ConvBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size=3, stride=1, padding=0, bias=True, max_pool=True):\n",
    "        super(ConvBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding, bias=bias)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels, eps=1e-03)\n",
    "        self.conv2 = nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding, bias=bias)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels, eps=1e-03)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.maxpool = nn.MaxPool2d(2, 2) if max_pool else None\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.relu(x)\n",
    "        if self.maxpool is not None:\n",
    "            x = self.maxpool(x)\n",
    "        x = self.dropout(x)\n",
    "        return x\n",
    "\n",
    "class NAA(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NAA, self).__init__()\n",
    "        self.encoder = torch.nn.Sequential(\n",
    "            ConvBlock(1, 8, kernel_size=3, bias=True),\n",
    "            ConvBlock(8, 16, kernel_size=3, bias=True),\n",
    "            ConvBlock(16, 32, kernel_size=3, bias=True),\n",
    "            ConvBlock(32, 64, kernel_size=3, bias=True, max_pool=False),\n",
    "            ConvBlock(64, 128, kernel_size=3, bias=True, max_pool=False),\n",
    "        )\n",
    "        self.mean = nn.Conv2d(128, 128, kernel_size=3, stride=1, padding=0, bias=True)\n",
    "        self.logvar = nn.Conv2d(128, 128, kernel_size=3, stride=1, padding=0, bias=True)\n",
    "        self.mean_relu = nn.ReLU()\n",
    "        self.logvar_relu = nn.ReLU()\n",
    "        self.decoder = torch.nn.Sequential(\n",
    "            nn.ConvTranspose2d(128, 128, kernel_size=3, stride=2, padding=0, bias=True),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            ConvBlock(128, 64, kernel_size=3, bias=True, max_pool=False),\n",
    "            nn.ConvTranspose2d(64, 64, kernel_size=3, stride=2, padding=0, bias=True),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            ConvBlock(64, 32, kernel_size=3, bias=True, max_pool=False),\n",
    "            nn.ConvTranspose2d(32, 32, kernel_size=3, stride=2, padding=0, bias=True),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            ConvBlock(32, 16, kernel_size=3, bias=True, max_pool=False),\n",
    "            nn.ConvTranspose2d(16, 16, kernel_size=3, stride=2, padding=0, bias=True),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            ConvBlock(16, 8, kernel_size=3, bias=True, max_pool=False),\n",
    "            nn.ConvTranspose2d(8, 8, kernel_size=3, stride=2, padding=0, bias=True),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            ConvBlock(8, 1, kernel_size=3, bias=True, max_pool=False),\n",
    "        )\n",
    "        self.final = nn.Sequential(\n",
    "            nn.Conv2d(1, 1, kernel_size=1, stride=1, padding=0, bias=True),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def reparameterize(self, mean, logvar):\n",
    "        std = torch.exp(0.5*logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mean + eps*std\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        mean = self.mean_relu(self.mean(x))\n",
    "        logvar = self.logvar_relu(self.logvar(x))\n",
    "        z = self.reparameterize(mean, logvar)\n",
    "        x = self.decoder(z)\n",
    "        return x"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Module 3: Prior UNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "peter",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
